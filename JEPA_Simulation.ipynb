{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5969df45",
   "metadata": {},
   "source": [
    "# AetherMind JEPA Simulation\n",
    "This notebook demonstrates the **Joint Embedding Predictive Architecture (JEPA)** controlling a simulated vehicle.\n",
    "The agent learns to predict the physics of the world in real-time. High prediction error (\"Energy\") represents surprise, triggering a safety reflex (Braking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Add project root to sys.path\n",
    "sys.path.append(os.path.abspath(os.getcwd()))\n",
    "\n",
    "try:\n",
    "    from brain.jepa_aligner import JEPAAligner\n",
    "    print(\"Success: AetherMind modules imported.\")\n",
    "except ImportError:\n",
    "    print(\"Error: Could not import AetherMind modules. Ensure you are running this from the project root.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6689c33",
   "metadata": {},
   "source": [
    "## Define Simulation World\n",
    "A simple class to simulate a vehicle moving towards a wall. It includes a \"Sudden Surprise\" event at step 30 to test the JEPA's reaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVehicleSimulator:\n",
    "    def __init__(self):\n",
    "        self.distance_to_wall = 100.0\n",
    "        self.speed = 2.0\n",
    "        self.step = 0\n",
    "    \n",
    "    def update(self, action):\n",
    "        \"\"\"\n",
    "        Updates the vehicle state based on action.\n",
    "        Action: 'accel' (+1 speed), 'brake' (-1 speed), 'maintain' (0 change)\n",
    "        \"\"\"\n",
    "        self.step += 1\n",
    "        \n",
    "        # Physics\n",
    "        if action == 'accel':\n",
    "            self.speed += 0.5\n",
    "        elif action == 'brake':\n",
    "            self.speed -= 1.0\n",
    "            \n",
    "        self.speed = max(0.0, self.speed) # No reverse\n",
    "        \n",
    "        # Move\n",
    "        self.distance_to_wall -= self.speed\n",
    "        \n",
    "        # Surprise Event at step 30 (Erratic slip or sudden obstacle jump)\n",
    "        if self.step == 30:\n",
    "            self.distance_to_wall -= 20 # Sudden jump closer!\n",
    "            \n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_state(self):\n",
    "        # Return normalized vector [distance_norm, speed_norm]\n",
    "        # Dimensions matching JEPA (let's use 16 as define in app.py or generic 1024)\n",
    "        # We'll use small dimension for demo\n",
    "        vec = np.zeros(16)\n",
    "        vec[0] = max(0, self.distance_to_wall) / 100.0\n",
    "        vec[1] = self.speed / 10.0\n",
    "        return vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1061b8",
   "metadata": {},
   "source": [
    "## Initialize Agent & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize JEPA Brain\n",
    "# Using 16 dimensions as per our text simulation standards\n",
    "jepa = JEPAAligner(dimension=16, energy_threshold=0.1)\n",
    "\n",
    "# Initialize Simulator\n",
    "sim = SimpleVehicleSimulator()\n",
    "last_state = np.zeros(16)\n",
    "\n",
    "print(\"System Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37734b",
   "metadata": {},
   "source": [
    "## Run Simulation Loop\n",
    "The loop runs for 50 ticks.\n",
    "Observe how the **Energy** (Surprise) spikes at Step 30, causing the Agent to switch from `maintain` to `brake`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bae208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'STEP':<6} {'DIST':<10} {'SPEED':<10} {'ENERGY':<10} {'ACTION'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i in range(51):\n",
    "    # 1. Prediction (JEPA Energy)\n",
    "    # How surprising is the current state given the last state?\n",
    "    current_state_vec = sim.get_state()\n",
    "    \n",
    "    # Calculate Energy (Prediction Error)\n",
    "    energy = jepa.compute_energy(last_state, current_state_vec)\n",
    "    \n",
    "    # 2. Learning\n",
    "    # Update internal world model to predict this transition next time\n",
    "    jepa.update_world_model(last_state, current_state_vec, learning_rate=0.1)\n",
    "    \n",
    "    # 3. Decision Logic based on \"Surprise\" (Energy)\n",
    "    action = \"maintain\"\n",
    "    \n",
    "    if energy > 0.4:\n",
    "        action = \"brake\" # Surprise! Slow down to gather info/safety\n",
    "    elif sim.distance_to_wall < 10:\n",
    "        action = \"brake\" # Hard safety limit\n",
    "    elif sim.distance_to_wall > 20:\n",
    "        action = \"accel\"\n",
    "        \n",
    "    # 4. Execute Action\n",
    "    last_state = current_state_vec\n",
    "    sim.update(action)\n",
    "    \n",
    "    # Log\n",
    "    dist_val = current_state_vec[0] * 100\n",
    "    speed_val = current_state_vec[1] * 10\n",
    "    print(f\"{i:<6} {dist_val:<10.1f} {speed_val:<10.1f} {energy:<10.4f} {action}\")\n",
    "    \n",
    "    if dist_val <= 0:\n",
    "        print(\"\\nðŸ’¥ CRASH! Simulation Ended.\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
